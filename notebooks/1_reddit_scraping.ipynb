{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Scraping for Clinical Trial Recruitment\n",
    "\n",
    "This notebook handles the ethical scraping of Reddit data to identify potential clinical trial participants.\n",
    "\n",
    "OUTPUT:\n",
    "- A json file containing the scraped data, with each post as a separate entry with its comments\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Adjust the constants in the Constants section as needed\n",
    "- You will need to have a credentials.json file in the config directory, see config/credentials.json.example for the format\n",
    "- Run the entire notebook to scrape the data and save it to a json file\n",
    "\n",
    "## Setup and Configuration\n",
    "1. Uses PRAW for Reddit API access\n",
    "2. Scrapes data from Reddit using search functionality with keywords\n",
    "3. Ensures user privacy\n",
    "4. Saves data in structured format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_COMMENTS_PER_POST = 10\n",
    "POST_LIMIT = 100\n",
    "\n",
    "# Define target subreddits related to health conditions, this is just a starting point, we can add more subreddits if needed\n",
    "SUBREDDITS = [\n",
    "    'ChronicIllness',\n",
    "    'ChronicPain',\n",
    "    'medicine',\n",
    "    'autoimmune'\n",
    "]\n",
    "\n",
    "# Keywords to filter relevant posts, similarly this is just a starting point, we can add more keywords if needed\n",
    "KEYWORDS = [\n",
    "    'clinical trial',\n",
    "    'medical study',\n",
    "    'research study',\n",
    "    'treatment option',\n",
    "    'new treatment',\n",
    "    'experimental treatment',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from config file\n",
    "def load_credentials():\n",
    "    try:\n",
    "        with open('../config/credentials.json', 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"credentials.json not found in config directory\")\n",
    "        raise\n",
    "\n",
    "# Initialize Reddit API client\n",
    "def init_reddit_client(credentials):\n",
    "    \"\"\"Initialize Reddit API client\n",
    "    \n",
    "    Sample credentials.json:\n",
    "    {\n",
    "        \"reddit\": {\n",
    "            \"client_id\": \"your_client_id\",\n",
    "            \"client_secret\": \"your_client_secret\",\n",
    "            \"user_agent\": \"your_user_agent\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    return praw.Reddit(\n",
    "        client_id=credentials['reddit']['client_id'],\n",
    "        client_secret=credentials['reddit']['client_secret'],\n",
    "        user_agent=credentials['reddit']['user_agent']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_data(text):\n",
    "    \"\"\"Remove or mask potentially identifying information\"\"\"\n",
    "    # TODO: Currently just a placeholder. Implement more sophisticated anonymization if needed\n",
    "    return text\n",
    "\n",
    "def scrape_subreddit(reddit, subreddit_name, post_limit=POST_LIMIT):\n",
    "    \"\"\"Scrape posts and comments from a subreddit\"\"\"\n",
    "    LIMIT_PER_KEYWORD = post_limit // len(KEYWORDS)\n",
    "\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts_data = []\n",
    "    \n",
    "    try:\n",
    "        # Search for each keyword\n",
    "        for keyword in KEYWORDS:\n",
    "            logger.info(f\"Searching for '{keyword}' in r/{subreddit_name}...\")\n",
    "            # Use Reddit's search functionality\n",
    "            for post in subreddit.search(keyword, limit=LIMIT_PER_KEYWORD, sort='new'):\n",
    "                # Skip if we already have this post (from a different keyword search)\n",
    "                if any(p['post_id'] == post.id for p in posts_data):\n",
    "                    continue\n",
    "                    \n",
    "                post_data = {\n",
    "                    'post_id': post.id,\n",
    "                    'author': post.author.name if post.author else None,\n",
    "                    'subreddit': subreddit_name,\n",
    "                    'title': anonymize_data(post.title),\n",
    "                    'text': anonymize_data(post.selftext),\n",
    "                    'created_utc': datetime.fromtimestamp(post.created_utc).isoformat(),\n",
    "                    'score': post.score,\n",
    "                    'matching_keyword': keyword,  # Track which keyword matched\n",
    "                    'comments': []\n",
    "                }\n",
    "                \n",
    "                # Get comments\n",
    "                post.comments.replace_more(limit=0)\n",
    "                for comment in post.comments[:MAX_COMMENTS_PER_POST]:\n",
    "                    comment_data = {\n",
    "                        'comment_id': comment.id,\n",
    "                        'text': anonymize_data(comment.body),\n",
    "                        'score': comment.score,\n",
    "                        'author': comment.author.name if comment.author else None,\n",
    "                        'created_utc': datetime.fromtimestamp(comment.created_utc).isoformat()\n",
    "                    }\n",
    "                    post_data['comments'].append(comment_data)\n",
    "                \n",
    "                posts_data.append(post_data)\n",
    "                # time.sleep(2)  # Rate limiting\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error scraping subreddit {subreddit_name}: {str(e)}\")\n",
    "        \n",
    "    return posts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename='../data/raw_reddit_data.json'):\n",
    "    \"\"\"Save scraped data to file\"\"\"\n",
    "    Path('../data').mkdir(exist_ok=True)\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    logger.info(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load credentials and initialize Reddit client\n",
    "    credentials = load_credentials()\n",
    "    reddit = init_reddit_client(credentials)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # Scrape each subreddit\n",
    "    for subreddit in SUBREDDITS:\n",
    "        logger.info(f\"Scraping r/{subreddit}...\")\n",
    "        subreddit_data = scrape_subreddit(reddit, subreddit)\n",
    "        all_data.extend(subreddit_data)\n",
    "        logger.info(f\"Collected {len(subreddit_data)} posts from r/{subreddit}\")\n",
    "        \n",
    "    # Save data\n",
    "    save_data(all_data)\n",
    "\n",
    "def load_saved_data():\n",
    "    \"\"\"Load the saved data and create a DataFrame for analysis preview\"\"\"\n",
    "    with open('../data/raw_reddit_data.json', 'r', encoding='utf-8') as f:\n",
    "        all_data = json.load(f)\n",
    "    # Create DataFrame for analysis preview\n",
    "    df = pd.json_normalize(\n",
    "        all_data, \n",
    "        record_path='comments',\n",
    "        meta=['post_id', 'subreddit', 'title', 'text', 'score', \n",
    "              'created_utc', 'matching_keyword'],\n",
    "        record_prefix='comment_',  # Prefix for comment fields\n",
    "        meta_prefix='post_'        # Prefix for post fields\n",
    "    )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Scraping r/ChronicIllness...\n",
      "INFO:__main__:Searching for 'clinical trial' in r/ChronicIllness...\n",
      "INFO:__main__:Searching for 'medical study' in r/ChronicIllness...\n",
      "INFO:__main__:Searching for 'research study' in r/ChronicIllness...\n",
      "INFO:__main__:Searching for 'treatment option' in r/ChronicIllness...\n",
      "INFO:__main__:Searching for 'new treatment' in r/ChronicIllness...\n",
      "INFO:__main__:Searching for 'experimental treatment' in r/ChronicIllness...\n",
      "INFO:__main__:Collected 84 posts from r/ChronicIllness\n",
      "INFO:__main__:Scraping r/ChronicPain...\n",
      "INFO:__main__:Searching for 'clinical trial' in r/ChronicPain...\n",
      "INFO:__main__:Searching for 'medical study' in r/ChronicPain...\n",
      "INFO:__main__:Searching for 'research study' in r/ChronicPain...\n",
      "INFO:__main__:Searching for 'treatment option' in r/ChronicPain...\n",
      "INFO:__main__:Searching for 'new treatment' in r/ChronicPain...\n",
      "INFO:__main__:Searching for 'experimental treatment' in r/ChronicPain...\n",
      "INFO:__main__:Collected 90 posts from r/ChronicPain\n",
      "INFO:__main__:Scraping r/medicine...\n",
      "INFO:__main__:Searching for 'clinical trial' in r/medicine...\n",
      "INFO:__main__:Searching for 'medical study' in r/medicine...\n",
      "INFO:__main__:Searching for 'research study' in r/medicine...\n",
      "INFO:__main__:Searching for 'treatment option' in r/medicine...\n",
      "INFO:__main__:Searching for 'new treatment' in r/medicine...\n",
      "INFO:__main__:Searching for 'experimental treatment' in r/medicine...\n",
      "INFO:__main__:Collected 85 posts from r/medicine\n",
      "INFO:__main__:Scraping r/autoimmune...\n",
      "INFO:__main__:Searching for 'clinical trial' in r/autoimmune...\n",
      "INFO:__main__:Searching for 'medical study' in r/autoimmune...\n",
      "INFO:__main__:Searching for 'research study' in r/autoimmune...\n",
      "INFO:__main__:Searching for 'treatment option' in r/autoimmune...\n",
      "INFO:__main__:Searching for 'new treatment' in r/autoimmune...\n",
      "INFO:__main__:Searching for 'experimental treatment' in r/autoimmune...\n",
      "INFO:__main__:Collected 73 posts from r/autoimmune\n",
      "INFO:__main__:Data saved to ../data/raw_reddit_data.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  comment_comment_id                                       comment_text  \\\n",
      "0            ltxeqb4  Hey, I am so sorry you are dealing with this. ...   \n",
      "1            ltxqenu  Yeah it’s always frustrating, I get the commen...   \n",
      "2            loqe5s9                                          [deleted]   \n",
      "3            lgh9vv6  You have to meet eligibility criteria for the ...   \n",
      "4            lgieezt  You can also look at prestigious universities ...   \n",
      "\n",
      "   comment_score  comment_author  comment_created_utc post_post_id  \\\n",
      "0              2  hotheadnchickn  2024-10-26T19:19:10      1gcwfy4   \n",
      "1              2       stradamus  2024-10-26T20:33:06      1gcwfy4   \n",
      "2              1            None  2024-09-24T14:42:35      1fohr4u   \n",
      "3              1         podge91  2024-08-04T13:21:58      1ejxi7j   \n",
      "4              1   Clawhands2022  2024-08-04T17:11:13      1ejxi7j   \n",
      "\n",
      "   post_subreddit                                         post_title  \\\n",
      "0  ChronicIllness  I hate having to accept my life without even k...   \n",
      "1  ChronicIllness  I hate having to accept my life without even k...   \n",
      "2  ChronicIllness  Unsure of which physician to put on my clinica...   \n",
      "3  ChronicIllness                                  Clinical trials?    \n",
      "4  ChronicIllness                                  Clinical trials?    \n",
      "\n",
      "                                           post_text post_score  \\\n",
      "0  I’ve had chronic nerve pain and severe, bilate...         14   \n",
      "1  I’ve had chronic nerve pain and severe, bilate...         14   \n",
      "2  I’m applying the the UDN (Undiagnosed ) progra...          6   \n",
      "3  (F25) How do I go about getting into clinical ...          1   \n",
      "4  (F25) How do I go about getting into clinical ...          1   \n",
      "\n",
      "      post_created_utc post_matching_keyword  \n",
      "0  2024-10-26T18:19:12        clinical trial  \n",
      "1  2024-10-26T18:19:12        clinical trial  \n",
      "2  2024-09-24T13:12:04        clinical trial  \n",
      "3  2024-08-04T11:12:12        clinical trial  \n",
      "4  2024-08-04T11:12:12        clinical trial  \n",
      "\n",
      "Data Collection Summary:\n",
      "Total posts collected: 288\n",
      "Total comments collected: 1569\n",
      "\n",
      "Subreddits distribution:\n",
      "post_subreddit\n",
      "medicine          681\n",
      "ChronicPain       411\n",
      "ChronicIllness    304\n",
      "autoimmune        173\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    df = load_saved_data()\n",
    "    print(df.head())\n",
    "    print(\"\\nData Collection Summary:\")\n",
    "    print(f\"Total posts collected: {df['post_post_id'].nunique()}\")\n",
    "    print(f\"Total comments collected: {len(df)}\")\n",
    "    print(\"\\nSubreddits distribution:\")\n",
    "    print(df['post_subreddit'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
